# Node.js Homework Project

## История

Перед началом, прочитай [сюжет задания](docs/story.md).

## Описание проекта

Проект представляет собой серверное приложение для агрегации данных из CSV файлов, содержащих информацию о расходах различных цивилизаций.

## Формат входных данных (CSV)

- `id` - ID записи (число)
- `civ` - цивилизация программиста (люди, желеобразные блобы с Юпитера, летающие макаронные монстры с Альфа Центавра)
- `developer_id` - уникальный id программиста (от 0 до 10_000_000_000_000)
- `date` - номер дня в году (от 0 до 364, високосных нет)
- `spend` - потрачено в кредитах для людей, в желеточках для блобов, в спагеттикоинах для макаронных монстров (от 0 до 1000)

Пример csv файла можо посмотреть [здесь](docs/examples/input.csv)

### Цивилизации

Цивилизации имеют следующие id:

- `humans` - Люди
- `blobs` - Желеобразные блобы с Юпитера
- `monsters` - Летающие макаронные монстры с Альфа Центавра

### Невалидные данные

Данные в CSV могут быть невалидны. Строки с такими данными стоит пропускать. Виды невалидных данных:

- Полностью невалидная строка - такая строка содержит случайный набор символов, запятые в строке отсутствуют
- Неизвестная цивилизация - значение `civ` отличается от валидных значений (`humans`, `blobs`, `monsters`)
- Отрицательное значение в поле `spend` - любое число меньше 0

Пример csv файла можо посмотреть [здесь](docs/examples/input-invalid.csv)

## Формат выходных данных (JSON)

```json
{
  "total_spend_galactic": number,    // общие расходы в галактических кредитах
  "rows_affected": number,           // количество обработанных (валидных) записей
  "less_spent_at": number,           // день года с минимальными расходами
  "big_spent_at": number,            // день года с максимальными расходами
  "less_spent_value": number,        // минимальная сумма расходов за день
  "big_spent_value": number,         // максимальная сумма расходов за день
  "average_spend_galactic": number,  // средние расходы в галактических кредитах
  "big_spent_civ": string,           // цивилизация с максимальными расходами
  "less_spent_civ": string,          // цивилизация с минимальными расходами
  "invalid_rows": number             // количество необработанных (невалидных) записей
}
```

## Доступные команды

### Запуск сервера

```bash
npm run start
```

Сервер запускается на стандартном порту 3000.

#### Запуск сервиса Ping

```bash
npm run ping
```

Данный сервис бесконечно шлет запросы в сервер выше, тем самым проверяя скорость ответа.

### Генерация CSV файла

```bash
npm run generate-csv-0.01gb # Генерация входящих данных размером 10 мб (только валидные данные)
npm run generate-csv-0.1gb # Генерация входящих данных размером 100 мб (только валидные данные)
npm run generate-csv-1gb # Генерация входящих данных размером 1 гб (только валидные данные)
npm run generate-csv-5gb # Генерация входящих данных размером 1 гб (только валидные данные)
npm run generate-csv-0.01gb-errors # Генерация входящих данных размером 10 мб (включет невалидные данные)
npm run generate-csv-0.1gb-errors # Генерация входящих данных размером 100 мб (включет невалидные данные)
npm run generate-csv-1gb-errors # Генерация входящих данных размером 1 гб (включет невалидные данные)
npm run generate-csv-5gb-errors # Генерация входящих данных размером 1 гб (включет невалидные данные)
```

Эта команда создаст большой CSV файл с тестовыми данными для последующей обработки.

### Отправка запроса

Следующая команда отправит запрос к серверу на базовый endpoint. Этот endpoint:

- Не способен обрабатывать большие файлы (от 1 гб)
- Служит начальным примером для реализации

```bash
npm run send-request-v1 # отправка сгенерированного CSV файла на сервер для обработки
```

Следующие две команды отправят запрос к серверу на enpoint, который реализуете вы:

```bash
npm run send-request-v2 # базовый ответ
npm run send-request-v2-stream # ответ в виде стрима, отправляющий промежуточные данные каждые 10 000 строк
```

## API Endpoints

### v1/stats:aggregate

Базовая версия эндпоинта для агрегации данных (неэффективная реализация). Выяснилось, что используя эту версию невозможно обработать файлы от 1 гб.

### v1/ping

Простой endpoint для проверки блокировки основного потока сервера. Если основной поток будет занят неэффективной операцией, то сервер не сможет обработать этот запрос долгое время, что отобразится в сервисе ping.

### v2/stats:aggregate `Реализовать самостоятельно`

Эффективная версия эндпоинта для агрегации данных, которая может обрабатывать файлы любого размера не задействуя большое количество памяти. Отправляет только итоговый ответ, после чего закрывает соединение.

Пример ответа можно посмотреть [здесь](docs/examples/ouput_base.json)

### v2/stats:aggregate_as_stream `Реализовать самостоятельно*`

Эффективная версия эндпоинта для агрегации данных, которая может обрабатывать файлы любого размера не задействуя большое количество памяти. Умеет отправлять промежуточные данные, при этом не закрывая соединение.

Пример ответа можно посмотреть [здесь](docs/examples/ouput_as_stream.json). Да, это будет невалидный JSON. Но это нормально, так как данные предназначены для обработки на лету.

## Метрики

### Healtcheck

Отображает загруженность основного потока. Показывается в консоли после запуска сервиса ping. Чем меньше RTT (Round Trip Time) - тем лучше, в нашем случае это значит что запросы меньше ждут момента когда сервер начнет их обрабатывать. Это свидетельствует о том, что EventLoop разгружен и не забит тяжелыми синхронными операциями.

1. CurrentRTT - RTT текущего healtcheck запроса
2. Requests - Количество отправленных healtcheck запросов
3. Max RTT - Максимальный RTT, который встретился во время проверки
4. Average RTT - Среднее RTT за последние 100 запросов

### Memory Usage

Отображает использование памяти v8 Heap. Отображается в консоли с сервером после его запуска. Здесь все просто, чем меньше - тем лучше.

1. Heap Used - Текущее использование памяти
2. Max Heap Used - Максимальный Heap Used, который встретился во время проверки

## Первые шаги

### nodejs

Для работы тебе нужно будет скачать версию nodejs, указанную в файле [.nvmrc](.nvmrc)

Советую скачать nvm и выполнить команду в терминале, тогда нужная версия установится и активируется автоматически

```bash
nvm use
```

Для работы нужно будет открыть 3 терминала. Убедись, что в каждом из них используется нужная версия nodejs:

```bash
node -v
```

### Сервисы

1. В первом терминале запусти сервер командой

   ```bash
   npm run start
   ```

   Ты сразу увидишь метрики твоего приложения, за памятью нужно будет следить!

   ```
   ------------------------
   Heap Used: 7MB
   Max Heap Used: 7MB
   ------------------------
   ```

2. Во втором терминале запусти сервис ping командой

   ```bash
   npm run ping
   ```

   На твой сервер стали отправляться healtcheck запросы. Чем меньше RTT - тем лучше, значит что сервер свободен для приема запросов.

   ```
   --------------------------------
   Current RTT: 2.49ms
   Requests: 993
   Max RTT: 4.90ms
   Average RTT (last 100 requests): 2.02ms
   --------------------------------
   ```

### Генерация первого запроса

В третьем терминале сгенерируй файл с данными. Для начала он будет размером в 100 мегабайт.

```bash
npm run generate-csv-0.1gb
```

Если хочешь, можешь сгенерировать файл, содержащий часть невалидных данных, командой:

```bash
npm run generate-csv-0.1gb-errors
```

У тебя должен был сгенерироваться файл `files/input.csv`. Теперь давай отправим запрос на твой работающий сервер. Используй команду

```bash
npm run send-request-v1
```

У тебя должен был сохраниться json файл `files/output.json`. Получилось! Но давай посмотрим на метрики? Кажется их пиковые значения уже очень велики! А что если попробовать отправить файл, где количество данных еще больше?

### Падение сервера

В третьем терминале снова сгенерируй файл с данными. Теперь он будет размером в 1 гб.

```bash
npm run generate-csv-1gb
```

Отправим запрос? Помня метрики из прошлого запроса, хорошего ничего ожидать не стоит.

```bash
npm run send-request-v1
```

Сервер упал :( Оказывается, что текущая реализация потребляет очень, очень, очень много оперативной памяти.

### Новая реализация!

Нужно восстановить сервис! Все в твоих руках!

**Важно.** Неоптимизированный эндпоинт использует функцию аггрегации данных, которая минифицирована и сложна для чтения. Тебе нужно будет написать собственную функцию аггрегации данных.

Не забывай, что валюты у разных цивилизаций отличаются. Необходимо использовать функцию `getExchangeRates`, чтобы конвертировать все валюты в галактические кредиты. Изменять функцию `getExchangeRates` запрещено.

## Задачи для реализации

1. Реализация эндпоинта v2/stats:aggregate
2. Сервис не должен падать при обработке файла размером в 5гб, сгенерированного с помощью команды
   ```bash
   npm run generate-csv-5gb
   ```
   и отправленного с помощью команды
   ```bash
   npm run send-request-v2
   ```
3. Обработка невалидных данных. Для генерации файла с невалидными данными используй команду

   ```bash
   npm run generate-csv-5gb-errors
   ```

4. Реализация эндпоинта v2/stats:aggregate_as_stream для потоковой отправки результатов. Эндпоинт не должен падать при обработке файла размером в 5гб, сгенерированного с помощью команды

   ```bash
   npm run generate-csv-5gb
   ```

   и отправленного с помощью команды

   ```bash
   npm run send-request-v2-stream
   ```

### Задача со звездочкой

Прямая работа с Buffer в реализации

### Вторая задача со звездочкой

Создание cli скрипта, который будет поточно:

- Генерировать данные
- Отправлять их на сервер
- Получать с сервера ответ
- Записывать результат на диск

Как видишь, в таком случае мы:

- пропускаем шаг сохранением csv файла с исходными данным на диск, чем экономим место
- запускаем только один npm скрипт вместо двух, чем экономим время

## Проверка решения

Данная задача проверяется методом кросс-проверки. Твое решение будет проверять другой студент. Ты также получишь работу, которую нужно будет оценить. Оценивай задачу в соотвествие с пунктом "Начисление баллов".

## Отправка решения

Свое решение нужно запаковать в zip архив и загрузить на любое доступное облачное хранлище. Рекомендуем использовать Яндекс Диск.

- Перед упаковкой решения не забудь удалть файлы input.csv и ouput.json из папки `files`. Проверящий студент сам их сгенерирует.
- Если у тебя macos рекомендуем запаковать папку через консольную команду, чтобы в архив легче читался в других ОС:
  ```bash
  zip -r solution.zip [путь/к/папке/с/кодом]
  ```

## Начисление баллов

Максимум за работу можно получить 100 баллов, из них:

Тебе также будут даны задачки со звездочкой - воспринимай их как дополнительный челендж для себя, а не источник баллов.

Ниже список с критериями оценки. Напротив каждого критерия - его оценка в баллах. На каждый критерий можно ответить только "да" или "нет". Если отвечаешь "да" - ставь все баллы критерия. Если нет - ставь 0.

1. Есть рабочее базовое решение `v2/stats:aggregate`. `50 баллов`

   Возможно работает с багами (неправильный расчет), но данные принмиаются, сервер не падает, а в output.json записывается json с нужными полями.

2. Решение работает без багов `15 баллов`

   Для проверки используйте эталонные данные из [папки с валидными данными](docs/correct_result/valid_only/input.csv) или из [папки с частично невалидными данными](docs/correct_result/with_invalid/input.csv). Скопируйте `input.csv` в папку `files` в корне проекта и отправьте запрос на сервер. Сравните полученный `output.json` с эталонным из соответствующей папки. Проверяйте только решение из базового эндпоинта `v2/stats:aggregate`.

3. Решение использует менее 28мб Heap при обработке 5гб файла `5 баллов`

   Отслеживай метрики в консоли во время обработки файла. Перед отправкой запроса перезапусти сервер, чтобы v8 heap был минимального размера. Перед отправкой запроса запомни значение метрики HeapUsed. После окончания запроса посмотри на значение MaxHeapUsed. Разница между вторым и первым значением и будет обозначать использование памяти.

   Например:

   ```
   ------------------------
   Heap Used: 7MB
   Max Heap Used: 23MB
   ------------------------
   ```

   Использование Heap = 23 - 7 = 16MB

4. MaxRTT во время решения - 300ms и менее `10 баллов`

   Отслеживай метрики сервиса Ping в консоли во время обработки файла.

5. Выполнена обработка невалидных данных `15 баллов`

   Приложение умеет обрабатывать файлы сгенерированные с невалидными данными. Для зачета этого критерия необходимо проверить решение на эталонных данных из [соответствующей папки](docs/correct_result/with_invalid/input.csv)

6. Есть рабочее решение `v2/stats:aggregate_as_stream` `5 баллов`

   Пример ответа можно посмотреть [здесь](docs/examples/ouput_as_stream.json). Это легче, чем может показаться!

7. (\*) Решение написано на буферах `0 баллов`

   Можешь создать отдельный ендпоинт v3 для решения на буферах.

8. (\*) Реализован один общий скрипт. `0 баллов`

   Можешь создать отдельный скрипт в папке cli для этого решения.

   [генерация данных] -> [отправка на сервер] -> [обработка на сервере] -> [отправка на клиент] -> [сохранение в файл на клиенте]
